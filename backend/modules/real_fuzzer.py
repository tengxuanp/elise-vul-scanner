"""
Real HTTP Fuzzer - Makes actual HTTP requests to test vulnerabilities
"""

import requests
import time
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from urllib.parse import urlencode, urlparse, parse_qs, urlunparse

# Import the payload evolver
try:
    from .ml.payload_evolver import payload_evolver
except ImportError:
    payload_evolver = None

logger = logging.getLogger(__name__)

@dataclass
class FuzzResult:
    """Result of a real fuzzing attempt"""
    endpoint: Dict[str, Any]
    payload: str
    response_status: int
    response_time: float
    response_headers: Dict[str, str]
    response_body: str
    response_length: int
    vulnerability_detected: bool
    detection_evidence: List[str]
    confidence_score: float
    vulnerability_type: str = "unknown"

class RealHTTPFuzzer:
    """Real HTTP fuzzer that makes actual requests"""
    
    def __init__(self, timeout: int = 10, max_retries: int = 3):
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = requests.Session()
        
        # Set realistic headers
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
    
    def fuzz_endpoint(self, endpoint: Dict[str, Any], payload: str) -> FuzzResult:
        """Fuzz a single endpoint with a payload using differential analysis"""
        url = endpoint["url"]
        param = endpoint["param"]
        method = endpoint["method"]
        
        logger.info(f"ðŸŽ¯ Fuzzing {url} with payload: {payload[:50]}...")
        
        try:
            # First, get baseline response with benign payload
            baseline_response = self._get_baseline_response(endpoint)
            
            # Then test with malicious payload
            if method.upper() == "GET":
                response = self._make_get_request(url, param, payload)
            elif method.upper() == "POST":
                response = self._make_post_request(url, param, payload)
            else:
                # Default to GET for other methods
                response = self._make_get_request(url, param, payload)
            
            # Analyze response for vulnerabilities using differential analysis
            vulnerability_detected, evidence, confidence = self._analyze_response_differential(
                endpoint, payload, response, baseline_response
            )
            
            # Determine vulnerability type
            vuln_type = self._classify_payload_type(payload)
            
            result = FuzzResult(
                endpoint=endpoint,
                payload=payload,
                response_status=response.status_code,
                response_time=response.elapsed.total_seconds(),
                response_headers=dict(response.headers),
                response_body=response.text,
                response_length=len(response.text),
                vulnerability_detected=vulnerability_detected,
                detection_evidence=evidence,
                confidence_score=confidence,
                vulnerability_type=vuln_type
            )
            
            logger.info(f"âœ… Fuzzing result: {response.status_code} - {'VULNERABLE' if vulnerability_detected else 'SAFE'} (confidence: {confidence:.2f})")
            
            # If we got an error response and payload evolver is available, try evolution
            # Trigger evolution for SQLite errors even if detected as vulnerable (to improve exploitation)
            should_evolve = (
                response.status_code == 500 and 
                payload_evolver is not None and 
                not hasattr(result, 'evolution_info') and  # Avoid infinite recursion
                (
                    not vulnerability_detected or  # Not detected as vulnerable
                    "SQLITE_ERROR" in response.text or  # SQLite error (even if detected)
                    "incomplete input" in response.text.lower() or  # Incomplete input error
                    "syntax error" in response.text.lower()  # SQL syntax error
                )
            )
            
            if should_evolve:
                
                logger.info(f"ðŸ”„ Attempting payload evolution for {url}")
                evolved_result = self._evolve_and_retry(endpoint, payload, result)
                if evolved_result and evolved_result.vulnerability_detected:
                    return evolved_result
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Error fuzzing {url}: {e}")
            return FuzzResult(
                endpoint=endpoint,
                payload=payload,
                response_status=0,
                response_time=0.0,
                response_headers={},
                response_body=f"Error: {str(e)}",
                response_length=len(f"Error: {str(e)}"),
                vulnerability_detected=False,
                detection_evidence=[f"Error: {str(e)}"],
                confidence_score=0.0,
                vulnerability_type="unknown"
            )
    
    def _get_baseline_response(self, endpoint: Dict[str, Any]) -> requests.Response:
        """Get baseline response with benign payload for comparison"""
        url = endpoint["url"]
        param = endpoint["param"]
        method = endpoint["method"]
        
        # Use benign payloads based on parameter type
        benign_payloads = {
            "id": "1",
            "userId": "1", 
            "productId": "1",
            "q": "test",
            "search": "test",
            "email": "test@example.com",
            "user": "test",
            "name": "test"
        }
        
        # Get appropriate benign payload
        benign_payload = benign_payloads.get(param, "test")
        
        logger.info(f"ðŸ“Š Getting baseline response with benign payload: {benign_payload}")
        
        try:
            if method.upper() == "GET":
                return self._make_get_request(url, param, benign_payload)
            elif method.upper() == "POST":
                return self._make_post_request(url, param, benign_payload)
            else:
                return self._make_get_request(url, param, benign_payload)
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to get baseline response: {e}")
            # Return a mock response if baseline fails
            mock_response = requests.Response()
            mock_response.status_code = 200
            mock_response._content = b'{"status":"error","message":"baseline_failed"}'
            return mock_response
    
    def _evolve_and_retry(self, endpoint: Dict[str, Any], original_payload: str, 
                         original_result: FuzzResult) -> Optional[FuzzResult]:
        """Evolve payload based on error response and retry"""
        try:
            # Analyze the error response
            error_analysis = payload_evolver.analyze_error_response(
                original_result.response_body, 
                original_result.response_status
            )
            
            logger.info(f"ðŸ” Error analysis: {error_analysis['error_type']} (confidence: {error_analysis['confidence']:.2f})")
            
            # Generate evolved payloads
            evolved_payloads = payload_evolver.evolve_payload(
                original_payload, 
                error_analysis, 
                endpoint
            )
            
            # Test the best evolved payload
            if evolved_payloads:
                best_evolved = evolved_payloads[0]
                evolved_payload = best_evolved["payload"]
                
                logger.info(f"ðŸ§¬ Testing evolved payload: {evolved_payload}")
                
                # Fuzz with evolved payload (avoid recursion by not calling fuzz_endpoint)
                url = endpoint["url"]
                param = endpoint["param"]
                method = endpoint["method"]
                
                if method.upper() == "GET":
                    response = self._make_get_request(url, param, evolved_payload)
                elif method.upper() == "POST":
                    response = self._make_post_request(url, param, evolved_payload)
                else:
                    response = self._make_get_request(url, param, evolved_payload)
                
                # Analyze response for vulnerabilities
                vulnerability_detected, evidence, confidence = self._analyze_response(
                    endpoint, evolved_payload, response
                )
                
                evolved_result = FuzzResult(
                    endpoint=endpoint,
                    payload=evolved_payload,
                    response_status=response.status_code,
                    response_time=response.elapsed.total_seconds(),
                    response_headers=dict(response.headers),
                    response_body=response.text,
                    response_length=len(response.text),
                    vulnerability_detected=vulnerability_detected,
                    detection_evidence=evidence,
                    confidence_score=confidence
                )
                
                # Add evolution metadata
                evolved_result.evolution_info = {
                    "original_payload": original_payload,
                    "evolution_reason": best_evolved.get("evolution_reason", "ML evolution"),
                    "error_type": error_analysis.get("error_type", "unknown"),
                    "confidence": error_analysis.get("confidence", 0.0)
                }
                
                if vulnerability_detected:
                    logger.info(f"âœ… Evolved payload found vulnerability!")
                else:
                    logger.info(f"ðŸ”„ Evolved payload still safe, trying next evolution...")
                
                return evolved_result
                    
        except Exception as e:
            logger.error(f"âŒ Error in payload evolution: {e}")
        
        return None
    
    def _make_get_request(self, url: str, param: str, payload: str) -> requests.Response:
        """Make a GET request with payload in query parameters"""
        # Parse URL and add payload to query parameters
        parsed = urlparse(url)
        query_params = parse_qs(parsed.query)
        query_params[param] = [payload]
        
        # Rebuild URL
        new_query = urlencode(query_params, doseq=True)
        new_url = urlunparse((
            parsed.scheme, parsed.netloc, parsed.path,
            parsed.params, new_query, parsed.fragment
        ))
        
        return self.session.get(new_url, timeout=self.timeout)
    
    def _make_post_request(self, url: str, param: str, payload: str) -> requests.Response:
        """Make a POST request with payload in form data"""
        data = {param: payload}
        return self.session.post(url, data=data, timeout=self.timeout)
    
    def _analyze_response(self, endpoint: Dict[str, Any], payload: str, response: requests.Response) -> tuple:
        """Analyze response for vulnerability indicators"""
        evidence = []
        confidence = 0.0
        vulnerability_detected = False
        
        # Get response details
        status_code = response.status_code
        response_text = response.text  # Keep original case for reflection detection
        response_text_lower = response_text.lower()
        response_headers = response.headers
        content_type = response_headers.get('content-type', '').lower()
        
        # Determine vulnerability type based on payload characteristics
        vuln_type = self._classify_payload_type(payload)
        
        if vuln_type == "sqli":
            if self._detect_sqli_vulnerability(response, payload):
                vulnerability_detected = True
                evidence.append("SQL injection vulnerability detected")
                confidence = 0.8
                
                # Additional evidence
                if status_code == 500:
                    evidence.append("Server error (500) suggests SQL syntax error")
                    confidence += 0.1
                elif "error" in response_text_lower and ("sql" in response_text_lower or "database" in response_text_lower):
                    evidence.append("Database error message in response")
                    confidence += 0.1
                elif len(response_text) > 5000 and "'" in payload:  # Large response with SQL payload
                    evidence.append("Unusually large response suggests data leakage")
                    confidence += 0.1
        
        elif vuln_type == "xss":
            if self._detect_xss_vulnerability(response, payload):
                vulnerability_detected = True
                evidence.append("XSS vulnerability detected")
                confidence = 0.7
                
                # Check if payload is reflected in response (case-insensitive)
                if payload.lower() in response_text_lower:
                    evidence.append("Payload reflected in response")
                    confidence += 0.2
                if "<script>" in response_text_lower:
                    evidence.append("Script tags found in response")
                    confidence += 0.1
        
        elif vuln_type == "rce":
            if self._detect_rce_vulnerability(response, payload):
                vulnerability_detected = True
                evidence.append("Command injection vulnerability detected")
                confidence = 0.8
                
                # Check for command output indicators
                if any(indicator in response_text_lower for indicator in ["root:", "uid=", "gid=", "total "]):
                    evidence.append("Command output detected in response")
                    confidence += 0.2
        
        elif vuln_type == "lfi":
            if self._detect_lfi_vulnerability(response, payload):
                vulnerability_detected = True
                evidence.append("Path traversal vulnerability detected")
                confidence = 0.7
                
                # Check for file content indicators
                if any(indicator in response_text_lower for indicator in ["root:", "bin:", "etc/", "usr/"]):
                    evidence.append("File system content detected")
                    confidence += 0.2
        
        elif vuln_type == "redirect":
            if self._detect_redirect_vulnerability(response, payload):
                vulnerability_detected = True
                evidence.append("Open redirect vulnerability detected")
                confidence = 0.6
                
                # Check for redirect headers
                if 'location' in response_headers:
                    location = response_headers['location']
                    if payload in location or "evil.com" in location:
                        evidence.append("Redirect to external domain detected")
                        confidence += 0.2
        
        # Normalize confidence to 0-1 range
        confidence = min(1.0, confidence)
        
        return vulnerability_detected, evidence, confidence
    
    def _analyze_response_differential(self, endpoint: Dict[str, Any], payload: str, response: requests.Response, baseline_response: requests.Response) -> tuple:
        """Analyze response for vulnerabilities using differential analysis"""
        evidence = []
        confidence = 0.0
        vulnerability_detected = False
        
        # Get response details
        status_code = response.status_code
        response_text = response.text
        response_text_lower = response_text.lower()
        response_length = len(response_text)
        
        # Get baseline details
        baseline_status = baseline_response.status_code
        baseline_text = baseline_response.text
        baseline_length = len(baseline_text)
        
        # Determine vulnerability type based on payload characteristics
        vuln_type = self._classify_payload_type(payload)
        
        logger.info(f"ðŸ” Differential analysis: Attack({status_code}, {response_length} chars) vs Baseline({baseline_status}, {baseline_length} chars)")
        
        if vuln_type == "sqli":
            vulnerability_detected, evidence, confidence = self._detect_sqli_differential(
                response, baseline_response, payload
            )
        elif vuln_type == "xss":
            vulnerability_detected, evidence, confidence = self._detect_xss_differential(
                response, baseline_response, payload
            )
        else:
            # For other types, fall back to original analysis
            vulnerability_detected, evidence, confidence = self._analyze_response(
                endpoint, payload, response
            )
        
        return vulnerability_detected, evidence, confidence
    
    def _detect_sqli_differential(self, response: requests.Response, baseline_response: requests.Response, payload: str) -> tuple:
        """Detect SQL injection using differential analysis"""
        evidence = []
        confidence = 0.0
        vulnerability_detected = False
        
        response_text = response.text
        response_text_lower = response_text.lower()
        baseline_text = baseline_response.text
        baseline_text_lower = baseline_text.lower()
        
        # Check for status code differences
        if response.status_code != baseline_response.status_code:
            if response.status_code == 500:
                evidence.append("Status code changed from 200 to 500 (SQL error)")
                confidence += 0.3
            elif response.status_code == 200 and baseline_response.status_code != 200:
                evidence.append("Status code changed to 200 (possible SQL injection)")
                confidence += 0.2
        
        # Check for response length differences
        response_length = len(response_text)
        baseline_length = len(baseline_text)
        length_diff = abs(response_length - baseline_length)
        
        if length_diff > 1000:  # Significant length difference
            if response_length > baseline_length:
                evidence.append(f"Response significantly longer ({response_length} vs {baseline_length} chars)")
                confidence += 0.2
            else:
                evidence.append(f"Response significantly shorter ({response_length} vs {baseline_length} chars)")
                confidence += 0.1
        
        # Check for SQL error messages
        sql_errors = [
            "sqlite_error", "mysql_error", "postgresql_error", "syntax error",
            "near", "unexpected", "incomplete input", "database error"
        ]
        
        has_sql_error = any(error in response_text_lower for error in sql_errors)
        baseline_has_sql_error = any(error in baseline_text_lower for error in sql_errors)
        
        if has_sql_error and not baseline_has_sql_error:
            evidence.append("SQL error message appeared in response")
            confidence += 0.4
        
        # Check for sensitive data leakage (only if response is different)
        if response_text != baseline_text:
            # Check for email patterns
            import re
            email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
            response_emails = re.findall(email_pattern, response_text)
            baseline_emails = re.findall(email_pattern, baseline_text)
            
            if len(response_emails) > len(baseline_emails):
                evidence.append(f"Additional email addresses found ({len(response_emails)} vs {len(baseline_emails)})")
                confidence += 0.3
            
            # Check for password hash patterns
            hash_pattern = r'"[a-f0-9]{32,}"'
            response_hashes = re.findall(hash_pattern, response_text)
            baseline_hashes = re.findall(hash_pattern, baseline_text)
            
            if len(response_hashes) > len(baseline_hashes):
                evidence.append(f"Additional password hashes found ({len(response_hashes)} vs {len(baseline_hashes)})")
                confidence += 0.4
        
        # Determine if vulnerability is detected
        if confidence >= 0.3:  # Lower threshold for differential analysis
            vulnerability_detected = True
            evidence.append("SQL injection vulnerability detected via differential analysis")
        
        return vulnerability_detected, evidence, min(1.0, confidence)
    
    def _detect_xss_differential(self, response: requests.Response, baseline_response: requests.Response, payload: str) -> tuple:
        """Detect XSS using differential analysis"""
        evidence = []
        confidence = 0.0
        vulnerability_detected = False
        
        response_text = response.text
        response_text_lower = response_text.lower()
        baseline_text = baseline_response.text
        baseline_text_lower = baseline_text.lower()
        
        # Check if payload is reflected in response but not in baseline
        payload_lower = payload.lower()
        payload_reflected = payload_lower in response_text_lower
        baseline_reflected = payload_lower in baseline_text_lower
        
        if payload_reflected and not baseline_reflected:
            evidence.append("Payload reflected in response but not in baseline")
            confidence += 0.4
        
        # Check for HTML entities that might indicate filtering
        if "&lt;" in response_text or "&gt;" in response_text:
            if "&lt;" not in baseline_text and "&gt;" not in baseline_text:
                evidence.append("HTML entities appeared in response (possible XSS filtering)")
                confidence += 0.2
        
        # Check for script tags
        response_scripts = response_text_lower.count("<script>")
        baseline_scripts = baseline_text_lower.count("<script>")
        
        if response_scripts > baseline_scripts:
            evidence.append(f"Additional script tags found ({response_scripts} vs {baseline_scripts})")
            confidence += 0.3
        
        # Determine if vulnerability is detected
        if confidence >= 0.3:
            vulnerability_detected = True
            evidence.append("XSS vulnerability detected via differential analysis")
        
        return vulnerability_detected, evidence, min(1.0, confidence)
    
    def _classify_payload_type(self, payload: str) -> str:
        """Classify payload type based on content"""
        payload_lower = payload.lower()
        
        # XSS indicators (check first to avoid false positives)
        xss_indicators = ["<script>", "<img", "javascript:", "onerror", "onload", "<svg", "alert(", "onclick", "<iframe", "<body", "<div", "onmouseover"]
        if any(indicator in payload_lower for indicator in xss_indicators):
            return "xss"
        
        # Command injection indicators (check before SQLi to avoid false positives)
        rce_indicators = [";", "|", "&", "`", "$(", "ls", "cat", "whoami", "id", "pwd"]
        if any(indicator in payload_lower for indicator in rce_indicators):
            return "rce"
        
        # SQL injection indicators (more specific to avoid false positives)
        sqli_indicators = ["union", "select", "drop", "insert", "update", "delete", "--", "#", "/*", "*/"]
        if any(indicator in payload_lower for indicator in sqli_indicators):
            return "sqli"
        
        # Check for SQLi with quotes only if no other indicators
        if "'" in payload and not any(indicator in payload_lower for indicator in ["alert(", "<script>", "javascript:"]):
            return "sqli"
        
        # Path traversal indicators
        lfi_indicators = ["../", "..\\", "/etc/", "\\windows\\", "passwd", "shadow", "boot.ini"]
        if any(indicator in payload_lower for indicator in lfi_indicators):
            return "lfi"
        
        # Open redirect indicators
        redirect_indicators = ["http://", "https://", "//", "javascript:", "data:"]
        if any(indicator in payload_lower for indicator in redirect_indicators):
            return "redirect"
        
        return "unknown"
    
    def _is_sqli_payload(self, payload: str) -> bool:
        """Check if payload is SQL injection"""
        return self._classify_payload_type(payload) == "sqli"
    
    def _is_xss_payload(self, payload: str) -> bool:
        """Check if payload is XSS"""
        return self._classify_payload_type(payload) == "xss"
    
    def _is_rce_payload(self, payload: str) -> bool:
        """Check if payload is command injection"""
        return self._classify_payload_type(payload) == "rce"
    
    def _is_lfi_payload(self, payload: str) -> bool:
        """Check if payload is path traversal"""
        return self._classify_payload_type(payload) == "lfi"
    
    def _is_redirect_payload(self, payload: str) -> bool:
        """Check if payload is open redirect"""
        return self._classify_payload_type(payload) == "redirect"
    
    def _detect_sqli_vulnerability(self, response: requests.Response, payload: str) -> bool:
        """Detect SQL injection vulnerability"""
        status_code = response.status_code
        response_text = response.text.lower()
        content_type = response.headers.get('content-type', '').lower()
        
        # Check for SQL error indicators
        sql_errors = [
            "sql syntax", "mysql", "postgresql", "sqlite", "oracle",
            "sql server", "database error", "sql error", "syntax error",
            "invalid query", "table doesn't exist", "column doesn't exist"
        ]
        
        # Status code indicators
        if status_code == 500:
            return True
        
        # Error message indicators
        if any(error in response_text for error in sql_errors):
            return True
        
        # Check for data leakage patterns (more specific)
        if "'" in payload:
            # Look for specific data leakage indicators (more specific patterns)
            data_leakage_indicators = [
                "uid=", "gid=", "total ", "drwx", "-rw-", "bin/", "usr/",
                "root:", "daemon:", "nobody:", "www-data:"
            ]
            
            # Check for email/password patterns (more specific)
            email_password_patterns = [
                "email", "password", "user_id", "admin"
            ]
            
            # Only flag as vulnerable if we see actual data leakage indicators
            if any(indicator in response_text for indicator in data_leakage_indicators):
                return True
            
            # Check for email/password patterns but avoid false positives in HTML
            if any(pattern in response_text for pattern in email_password_patterns):
                # Make sure it's not just HTML content
                if not ('<html' in response_text or '<!doctype' in response_text):
                    # For JSON responses, look for specific data leakage patterns
                    if content_type.startswith('application/json'):
                        # Check for SENSITIVE data leakage patterns (not just any data)
                        sensitive_data_leakage = [
                            '"email":', '"password":', '"user_id":', '"admin"',
                            # Look for email patterns in name field (user data leakage)
                            '@juice-sh.op', '@owasp.org', 'admin@', 'user@'
                        ]
                        
                        # Check for password hash patterns (32+ character hex strings)
                        import re
                        password_hash_pattern = r'"[a-f0-9]{32,}"'
                        
                        # Check for business data patterns that should NOT be flagged
                        business_data_patterns = [
                            'Apple Juice', 'Orange Juice', 'Eggfruit Juice', 'Raspberry Juice',
                            'Lemon Juice', 'Banana Juice', 'T-Shirt', 'Mug', 'Hoodie',
                            'Sticker', 'Magnets', 'Iron-Ons', 'Temporary Tattoos'
                        ]
                        
                        # Only flag as vulnerable if we see actual sensitive data AND not business data
                        has_sensitive_data = (any(pattern in response_text for pattern in sensitive_data_leakage) or
                                            re.search(password_hash_pattern, response_text))
                        
                        has_business_data = any(pattern in response_text for pattern in business_data_patterns)
                        
                        if has_sensitive_data and not has_business_data:
                            return True
                    else:
                        return True
            
            # Check for unusual response patterns that suggest SQL injection
            # But avoid false positives on legitimate API responses and SPA pages
            if (len(response_text) > 10000 and 
                not content_type.startswith('text/html')):
                return True
            
            # Avoid false positives on SPA main pages (they return large HTML)
            if (content_type.startswith('text/html') and 
                len(response_text) > 10000 and
                ('<!doctype html>' in response_text or '<html' in response_text)):
                # This is likely a main SPA page, not a vulnerability
                return False
        
        return False
    
    def _detect_xss_vulnerability(self, response: requests.Response, payload: str) -> bool:
        """Detect XSS vulnerability by checking for payload reflection"""
        response_text = response.text
        response_text_lower = response_text.lower()
        payload_lower = payload.lower()
        
        # Primary check: Is the payload actually reflected in the response?
        if payload_lower in response_text_lower:
            return True
        
        # Check for HTML entities that might indicate XSS filtering
        if "&lt;" in response_text or "&gt;" in response_text:
            # If we see HTML entities, check if our payload was filtered
            if payload_lower.replace("<", "&lt;").replace(">", "&gt;") in response_text_lower:
                return True
        
        # Check for URL-encoded payload reflection
        import urllib.parse
        encoded_payload = urllib.parse.quote(payload)
        if encoded_payload.lower() in response_text_lower:
            return True
        
        # Check for double-encoded payload reflection
        double_encoded = urllib.parse.quote(encoded_payload)
        if double_encoded.lower() in response_text_lower:
            return True
        
        # Only check for specific XSS patterns if we have a suspicious payload
        # and the response is relatively small (to avoid false positives on large pages)
        if len(response_text) < 50000:  # Only check smaller responses
            xss_patterns = [
                "javascript:", "onerror=", "onload=", "onclick=", "alert("
            ]
            
            # Only flag if we see multiple XSS patterns AND they seem related to our payload
            pattern_count = sum(1 for pattern in xss_patterns if pattern in response_text_lower)
            if pattern_count >= 2:
                # Additional check: make sure this isn't just a normal page with scripts
                if not any(normal_page_indicator in response_text_lower for normal_page_indicator in [
                    "doctype html", "html lang", "head>", "body>", "meta charset"
                ]):
                    return True
        
        return False
    
    def _detect_rce_vulnerability(self, response: requests.Response, payload: str) -> bool:
        """Detect command injection vulnerability"""
        response_text = response.text.lower()
        
        # Check for command output indicators
        command_outputs = [
            "root:", "uid=", "gid=", "total ", "drwx", "-rw-", "bin/", "usr/",
            "linux", "darwin", "windows", "command not found", "permission denied"
        ]
        
        return any(output in response_text for output in command_outputs)
    
    def _detect_lfi_vulnerability(self, response: requests.Response, payload: str) -> bool:
        """Detect path traversal vulnerability"""
        response_text = response.text.lower()
        
        # Check for file system content
        file_indicators = [
            "root:", "bin:", "etc/", "usr/", "var/", "home/", "windows/",
            "system32", "drivers", "passwd", "shadow", "hosts"
        ]
        
        return any(indicator in response_text for indicator in file_indicators)
    
    def _detect_redirect_vulnerability(self, response: requests.Response, payload: str) -> bool:
        """Detect open redirect vulnerability"""
        status_code = response.status_code
        location_header = response.headers.get('location', '')
        
        # Check for redirect status codes
        if status_code in [301, 302, 303, 307, 308]:
            # Check if redirect goes to external domain
            if payload in location_header or "evil.com" in location_header:
                return True
        
        return False
